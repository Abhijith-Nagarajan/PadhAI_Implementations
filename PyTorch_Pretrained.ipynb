{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tOg8p_82PMZP",
        "2Uwr303fPY7Q",
        "3DI3eFfzoK_q",
        "J_2knKdIPAvZ"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyML890tZshdqo7N7hcAzQ7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijith-Nagarajan/PadhAI_Implementations/blob/main/PyTorch_Pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective ###\n",
        "\n",
        "*   Run pretrained models to fine tune last layers.\n",
        "*   Experiment with VGG, Inception and ResNet\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KRKrd-I883Ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Pre-Trained models"
      ],
      "metadata": {
        "id": "Oho0VhRx9G9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m_CKDbzs8zLZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "MKNo-6CO9XxH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "QwgrnnksCRxC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "tL0x2J0js2jU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else\"cpu\""
      ],
      "metadata": {
        "id": "aaAEY0VjW_D0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3Jf1C5P0fWX7",
        "outputId": "7687dc82-414e-40ba-f764-460da896ba2e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Building transforms for VGG and ResNet #####"
      ],
      "metadata": {
        "id": "tOg8p_82PMZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),\n",
        "                         (0.5,0.5,0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "M3dV5Pz3CEpk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),\n",
        "                         (0.5,0.5,0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "4zCztIDoP73p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Building the transforms for Inception #####"
      ],
      "metadata": {
        "id": "2Uwr303fPY7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform_inception = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(229),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),\n",
        "                         (0.5,0.5,0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "xW8DeSWxh1ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform_inception = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(229),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),\n",
        "                         (0.5,0.5,0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "1dWFDwV5h-be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Loading the dataset and data loaders #####"
      ],
      "metadata": {
        "id": "mCZyN9Nch2gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = datasets.CIFAR10(root='./data',train = True, download = True, transform = train_transform)\n",
        "test_df = datasets.CIFAR10(root='./data', train = False, download = True, transform = test_transform)"
      ],
      "metadata": {
        "id": "NTumasD89kDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7d83e3-e3ed-4349-e278-7aa2821194c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13065507.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_df, batch_size = 24, shuffle = True)"
      ],
      "metadata": {
        "id": "HY9rwWNgRcu8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_df, batch_size = 16, shuffle = True)"
      ],
      "metadata": {
        "id": "jBOa7PZShV8k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### VGG Model #####"
      ],
      "metadata": {
        "id": "Rt6ZsUe8jtFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Training from scratch ######"
      ],
      "metadata": {
        "id": "3DI3eFfzoK_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = models.vgg16_bn()"
      ],
      "metadata": {
        "id": "iI0ZPAf1jswm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vgg_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g7Sec3EizIU",
        "outputId": "61f86ea0-a2ae-4e73-8ae4-9a7d8c74c2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model.classifier[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3a0jYVLmhfU",
        "outputId": "860808eb-ecbc-4b2d-f0c6-4d28f1b0eba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model.classifier[6] = nn.Linear(in_features=4096, out_features = 10)"
      ],
      "metadata": {
        "id": "5lAgRrKCl2P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model.classifier[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVTlfsPYvAyt",
        "outputId": "664d64b1-7d5a-40cd-ebf8-8e328a9084bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=10, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Using a pretrained model ######\n",
        "\n",
        "1.  Load specific model and set pretrained = True\n",
        "2.  Set all the requires_grad to False\n",
        "3.  Modify the last layer of FFN according to the number of target classes.\n",
        "4.  Build model and evaluate performance.     \n",
        "\n"
      ],
      "metadata": {
        "id": "kt6ij5ZLMZtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Loading the model ######"
      ],
      "metadata": {
        "id": "tiM2nUyDuGG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_pretrained = models.vgg16_bn(pretrained = True)"
      ],
      "metadata": {
        "id": "LdU9dn8fmlB7"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in vgg_model_pretrained.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "3VhXRbsZu5Lv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_pretrained.classifier[6] = nn.Linear(in_features = 4096,out_features = 10)"
      ],
      "metadata": {
        "id": "_igBUa9JwPhz"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in vgg_model_pretrained.parameters():\n",
        "    if param.requires_grad:\n",
        "        print(param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIuxLl3ewbfo",
        "outputId": "2a43690b-43b3-447a-d90c-fcd1f350b5d3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 4096])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model_pretrained = vgg_model_pretrained.to(device)"
      ],
      "metadata": {
        "id": "Oy1V4s7upjk1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Training the model ######"
      ],
      "metadata": {
        "id": "mCED3_cfuKBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg_model_pretrained.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "INVwCY1XwsQc"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(dataloader, model, epochs):\n",
        "    loss_per_epoch = []\n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(dataloader,0):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(images)\n",
        "            #print(output) -> Displays probability for each class\n",
        "\n",
        "            #predicted_class = torch.argmax(output,1)\n",
        "            #print(predicted_class) -> Displays class with highest probability\n",
        "\n",
        "            # Compute the cross entropy loss\n",
        "            loss = loss_fn(output,labels)\n",
        "            #print(loss)\n",
        "\n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights and bias for the last layer\n",
        "            optimizer.step()\n",
        "\n",
        "            # Optimizing memory usage\n",
        "            del images, labels, output\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            if i%50==0:\n",
        "                print(f'Iteration {i}: Loss - {loss.item()}')\n",
        "\n",
        "        loss_per_epoch.append(loss.item())\n",
        "    return loss_per_epoch"
      ],
      "metadata": {
        "id": "Cdbq2c_kxG-R"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = training_loop(train_loader,vgg_model_pretrained,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3an01B8KOEJu",
        "outputId": "991129c9-8779-4685-c0d6-2bf28ea90e91"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Loss - 2.348021984100342\n",
            "Iteration 50: Loss - 1.6975477933883667\n",
            "Iteration 100: Loss - 1.5071234703063965\n",
            "Iteration 150: Loss - 1.3905903100967407\n",
            "Iteration 200: Loss - 1.862545371055603\n",
            "Iteration 250: Loss - 1.056376338005066\n",
            "Iteration 300: Loss - 1.5060253143310547\n",
            "Iteration 350: Loss - 1.2138941287994385\n",
            "Iteration 400: Loss - 1.4088847637176514\n",
            "Iteration 450: Loss - 1.3011606931686401\n",
            "Iteration 500: Loss - 1.0284245014190674\n",
            "Iteration 550: Loss - 1.4073139429092407\n",
            "Iteration 600: Loss - 1.2647435665130615\n",
            "Iteration 650: Loss - 1.2926669120788574\n",
            "Iteration 700: Loss - 1.7534215450286865\n",
            "Iteration 750: Loss - 1.330113172531128\n",
            "Iteration 800: Loss - 1.2406420707702637\n",
            "Iteration 850: Loss - 1.2468408346176147\n",
            "Iteration 900: Loss - 1.1193571090698242\n",
            "Iteration 950: Loss - 1.396403431892395\n",
            "Iteration 1000: Loss - 0.8315589427947998\n",
            "Iteration 1050: Loss - 1.3147289752960205\n",
            "Iteration 1100: Loss - 1.2102510929107666\n",
            "Iteration 1150: Loss - 1.0698049068450928\n",
            "Iteration 1200: Loss - 1.0850443840026855\n",
            "Iteration 1250: Loss - 0.9321085810661316\n",
            "Iteration 1300: Loss - 0.9586552381515503\n",
            "Iteration 1350: Loss - 1.0365253686904907\n",
            "Iteration 1400: Loss - 1.2662770748138428\n",
            "Iteration 1450: Loss - 2.012051820755005\n",
            "Iteration 1500: Loss - 1.7575162649154663\n",
            "Iteration 1550: Loss - 1.5560895204544067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop_checkpointing(dataloader, model, epochs):\n",
        "    '''\n",
        "    Checkpointing - At intermediate iterations, we store the weights if the current loss is smaller than the minimum loss\n",
        "    '''\n",
        "    loss_per_epoch = []\n",
        "    min_loss = 1000\n",
        "    best_model = dict()\n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(dataloader,0):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(images)\n",
        "            #print(output) -> Displays probability for each class\n",
        "\n",
        "            #predicted_class = torch.argmax(output,1)\n",
        "            #print(predicted_class) -> Displays class with highest probability\n",
        "\n",
        "            # Compute the cross entropy loss\n",
        "            loss = loss_fn(output,labels)\n",
        "            #print(loss)\n",
        "\n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights and bias for the last layer\n",
        "            optimizer.step()\n",
        "\n",
        "            # Optimizing memory usage\n",
        "            del images, labels, output\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            if i%50==0:\n",
        "                print(f'Iteration {i}: Loss - {loss.item()}')\n",
        "\n",
        "            if min_loss > loss.item():\n",
        "                min_loss = loss.item()\n",
        "                best_model = copy.deepcopy(model.state_dict())\n",
        "                print(f'Minimal Loss received: {min_loss}')\n",
        "\n",
        "        loss_per_epoch.append(loss.item())\n",
        "    return (loss_per_epoch, best_model)"
      ],
      "metadata": {
        "id": "W5RMM-RFsPII"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, best_model = training_loop_checkpointing(train_loader,vgg_model_pretrained,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjrOvAHKtD-2",
        "outputId": "8dd6b752-8f2f-4a67-8f4e-5ddaeb8315b3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Loss - 2.3050050735473633\n",
            "Minimal Loss received: 2.3050050735473633\n",
            "Minimal Loss received: 2.213153123855591\n",
            "Iteration 50: Loss - 2.3897459506988525\n",
            "Iteration 100: Loss - 2.343491554260254\n",
            "Iteration 150: Loss - 2.266019821166992\n",
            "Iteration 200: Loss - 2.407867431640625\n",
            "Iteration 250: Loss - 2.2948479652404785\n",
            "Minimal Loss received: 2.1996467113494873\n",
            "Iteration 300: Loss - 2.3947863578796387\n",
            "Iteration 350: Loss - 2.348727226257324\n",
            "Iteration 400: Loss - 2.2788479328155518\n",
            "Minimal Loss received: 2.196958303451538\n",
            "Iteration 450: Loss - 2.37304425239563\n",
            "Iteration 500: Loss - 2.3321406841278076\n",
            "Iteration 550: Loss - 2.318359136581421\n",
            "Iteration 600: Loss - 2.27799391746521\n",
            "Iteration 650: Loss - 2.454427480697632\n",
            "Iteration 700: Loss - 2.4177322387695312\n",
            "Iteration 750: Loss - 2.286395788192749\n",
            "Iteration 800: Loss - 2.353759527206421\n",
            "Minimal Loss received: 2.1958632469177246\n",
            "Iteration 850: Loss - 2.444622039794922\n",
            "Iteration 900: Loss - 2.3648664951324463\n",
            "Iteration 950: Loss - 2.331589460372925\n",
            "Iteration 1000: Loss - 2.455815553665161\n",
            "Iteration 1050: Loss - 2.4723193645477295\n",
            "Iteration 1100: Loss - 2.3323934078216553\n",
            "Iteration 1150: Loss - 2.366558790206909\n",
            "Iteration 1200: Loss - 2.3374011516571045\n",
            "Minimal Loss received: 2.1936588287353516\n",
            "Iteration 1250: Loss - 2.339925765991211\n",
            "Iteration 1300: Loss - 2.3267557621002197\n",
            "Iteration 1350: Loss - 2.29756498336792\n",
            "Minimal Loss received: 2.185314178466797\n",
            "Iteration 1400: Loss - 2.2304136753082275\n",
            "Iteration 1450: Loss - 2.407240629196167\n",
            "Iteration 1500: Loss - 2.4066483974456787\n",
            "Iteration 1550: Loss - 2.3887767791748047\n",
            "Iteration 1600: Loss - 2.397609233856201\n",
            "Iteration 1650: Loss - 2.3644731044769287\n",
            "Iteration 1700: Loss - 2.366387128829956\n",
            "Iteration 1750: Loss - 2.321592092514038\n",
            "Iteration 1800: Loss - 2.3862884044647217\n",
            "Minimal Loss received: 2.178215980529785\n",
            "Iteration 1850: Loss - 2.354573965072632\n",
            "Iteration 1900: Loss - 2.3747663497924805\n",
            "Iteration 1950: Loss - 2.4100725650787354\n",
            "Iteration 2000: Loss - 2.3724303245544434\n",
            "Iteration 2050: Loss - 2.314554452896118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now load the best weights and evaluate on test set\n",
        "vgg_model_pretrained.load_state_dict(best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEpKdEOZti4y",
        "outputId": "fcf78f9a-23c2-4e20-b6a6-e7f03307ce5b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimental ###"
      ],
      "metadata": {
        "id": "J_2knKdIPAvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[-0.6164,  0.0215, -0.6216, -0.5716,  0.4533,  0.1927, -0.5733, -0.2763,\n",
        "         -0.2323, -0.3006],\n",
        "        [ 0.1643,  0.4449, -0.5977, -0.1297,  0.0267,  0.1185,  0.1728, -0.0669,\n",
        "         -0.1361, -0.1916],\n",
        "        [ 0.1648,  0.1427,  0.1467,  0.0976,  0.0916, -0.3285,  0.0614,  0.4257,\n",
        "         -0.4803, -0.2412],\n",
        "        [ 0.0194,  0.2434, -0.5762,  0.2695, -0.1636, -0.0406,  0.2130,  0.3534,\n",
        "          0.1299, -0.2418],\n",
        "        [-0.0971, -0.0446, -0.4116, -0.1931,  0.4207,  0.3583,  0.1577,  0.0175,\n",
        "         -0.1576,  0.0654],\n",
        "        [-0.0044,  0.2831, -0.3403,  0.2046, -0.4859, -0.0732, -0.1655,  0.1770,\n",
        "         -0.1208,  0.0334],\n",
        "        [-0.5923,  0.1234, -0.1038, -0.1409, -0.1928,  0.7160, -0.0210, -0.1204,\n",
        "         -0.1741, -0.4065],\n",
        "        [-0.0934,  0.2186, -0.5412,  0.5249,  0.0304,  0.4698, -0.1730, -0.1892,\n",
        "          0.0085,  0.4449]])"
      ],
      "metadata": {
        "id": "_4aQ4IubPAaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(t,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv5Ma_KhPGkk",
        "outputId": "d7563c38-6f46-4e6a-aa35-dd34ede7e8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 1, 7, 7, 4, 1, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_loader,0):\n",
        "    image, label = data\n",
        "\n",
        "    print(label)\n",
        "    if i==1:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SILOuX1S0mn8",
        "outputId": "8f63070f-eb66-444c-de4e-028ab7caccdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 3, 5, 3, 3, 3, 3])\n",
            "tensor([7, 3, 1, 6, 8, 9, 3, 5])\n"
          ]
        }
      ]
    }
  ]
}